{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出适合OneHotEncoder的数据\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/686452650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "X_train = np.load('../Training data/X_train.npy')  # 特征 (1000, 111)\n",
    "y_train = np.load('../Training data/y_train.npy')  # 目标 (1000, 11)\n",
    "x_test=np.load(\"../Testing data/X_test.npy\")\n",
    "\n",
    "\n",
    "x_train = pd.DataFrame(X_train).rename(columns={i: f\"x_{i}\" for i in range(111)})\n",
    "y_train = pd.DataFrame(y_train).rename(columns={i: f\"y_{i}\" for i in range(11)})\n",
    "x_test = pd.DataFrame(x_test).rename(columns={i: f\"x_{i}\" for i in range(111)})\n",
    "\n",
    "#中位数填补\n",
    "for column in x_train.columns:\n",
    "    x_train.fillna({column: x_train[column].median()}, inplace=True)\n",
    "    x_test.fillna({column: x_test[column].median()}, inplace=True)\n",
    "\n",
    "\n",
    "# 找出非零值少于1%的列\n",
    "threshold = 0.01  # 或者任何认为合适的值\n",
    "cols_to_drop = [col for col in x_train.columns if (x_train[col] != 0).mean() < threshold]\n",
    "\n",
    "# 删除这些列\n",
    "x_train.drop(columns=cols_to_drop, inplace=True)\n",
    "x_test.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# 特征缩放\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.fit_transform(x_test), columns=x_test.columns)\n",
    "\n",
    "\n",
    "# 划分出来百分之二十的测试集\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 将处理后的DataFrame转换回NumPy数组\n",
    "X_train_processed = X_train.to_numpy()\n",
    "# 现在X_train_processed是预处理后的数据，可以用于模型训练\n",
    "len(X_train_processed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型结构\n",
    "shared_input = Input(shape=(len(X_train_processed[0]), ), name='shared_input')\n",
    "shared_layer = Dense(128, activation='sigmoid')(shared_input)\n",
    "shared_layer = Dense(64, activation='relu')(shared_layer)\n",
    "shared_layer = Dense(32, activation='relu')(shared_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义Specific部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in range(11):\n",
    "    task_output = Dense(16,  activation='sigmoid', name=f'task_{i}_hidden')(shared_layer)\n",
    "    task_output = Dense(1,  activation='sigmoid', name=f'task_{i}_output')(task_output)\n",
    "    outputs.append(task_output)\n",
    "outputs = Concatenate(axis=-1)(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型并输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.6726 - precision: 0.1670 - recall: 0.2667 - val_loss: 0.5713 - val_precision: 0.0504 - val_recall: 0.1741\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5695 - precision: 0.0532 - recall: 0.1739 - val_loss: 0.5572 - val_precision: 0.0500 - val_recall: 0.1905\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5628 - precision: 0.0516 - recall: 0.1986 - val_loss: 0.5562 - val_precision: 0.0500 - val_recall: 0.1978\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5704 - precision: 0.0531 - recall: 0.1986 - val_loss: 0.5561 - val_precision: 0.0498 - val_recall: 0.1909\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5702 - precision: 0.0539 - recall: 0.1930 - val_loss: 0.5558 - val_precision: 0.0500 - val_recall: 0.1931\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5603 - precision: 0.0520 - recall: 0.1959 - val_loss: 0.5556 - val_precision: 0.0497 - val_recall: 0.1913\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5587 - precision: 0.0523 - recall: 0.1946 - val_loss: 0.5557 - val_precision: 0.0498 - val_recall: 0.1891\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5672 - precision: 0.0542 - recall: 0.1949 - val_loss: 0.5556 - val_precision: 0.0500 - val_recall: 0.1909\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5643 - precision: 0.0540 - recall: 0.1927 - val_loss: 0.5552 - val_precision: 0.0496 - val_recall: 0.1894\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5621 - precision: 0.0547 - recall: 0.1927 - val_loss: 0.5558 - val_precision: 0.0506 - val_recall: 0.1821\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5564 - precision: 0.1468 - recall: 0.1893 - val_loss: 0.5552 - val_precision: 0.1174 - val_recall: 0.1854\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5546 - precision: 0.1450 - recall: 0.1893 - val_loss: 0.5565 - val_precision: 0.1177 - val_recall: 0.1778\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5494 - precision: 0.1953 - recall: 0.1883 - val_loss: 0.5561 - val_precision: 0.1009 - val_recall: 0.1774\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5521 - precision: 0.1779 - recall: 0.1877 - val_loss: 0.5553 - val_precision: 0.1282 - val_recall: 0.1596\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5459 - precision: 0.1865 - recall: 0.1752 - val_loss: 0.5590 - val_precision: 0.1104 - val_recall: 0.1854\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5465 - precision: 0.1749 - recall: 0.1963 - val_loss: 0.5580 - val_precision: 0.1178 - val_recall: 0.1789\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5473 - precision: 0.1769 - recall: 0.1916 - val_loss: 0.5578 - val_precision: 0.1284 - val_recall: 0.1643\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5388 - precision: 0.1818 - recall: 0.1857 - val_loss: 0.5621 - val_precision: 0.1281 - val_recall: 0.1734\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5425 - precision: 0.1847 - recall: 0.1865 - val_loss: 0.5601 - val_precision: 0.1189 - val_recall: 0.1497\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5414 - precision: 0.3114 - recall: 0.1880 - val_loss: 0.5596 - val_precision: 0.1127 - val_recall: 0.1625\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5426 - precision: 0.2913 - recall: 0.1887 - val_loss: 0.5601 - val_precision: 0.3261 - val_recall: 0.1610\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5339 - precision: 0.3517 - recall: 0.1913 - val_loss: 0.5650 - val_precision: 0.1645 - val_recall: 0.1628\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5309 - precision: 0.3602 - recall: 0.1967 - val_loss: 0.5631 - val_precision: 0.3164 - val_recall: 0.1607\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5347 - precision: 0.3162 - recall: 0.1963 - val_loss: 0.5624 - val_precision: 0.2198 - val_recall: 0.1610\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5227 - precision: 0.3484 - recall: 0.1968 - val_loss: 0.5649 - val_precision: 0.3089 - val_recall: 0.1512\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5186 - precision: 0.3322 - recall: 0.1863 - val_loss: 0.5714 - val_precision: 0.1932 - val_recall: 0.1559\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5218 - precision: 0.3675 - recall: 0.1974 - val_loss: 0.5673 - val_precision: 0.1608 - val_recall: 0.1570\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5228 - precision: 0.3324 - recall: 0.1931 - val_loss: 0.5681 - val_precision: 0.2139 - val_recall: 0.1519\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5241 - precision: 0.4809 - recall: 0.1962 - val_loss: 0.5721 - val_precision: 0.1844 - val_recall: 0.1617\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5150 - precision: 0.5367 - recall: 0.2044 - val_loss: 0.5737 - val_precision: 0.1748 - val_recall: 0.1479\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5128 - precision: 0.4853 - recall: 0.1972 - val_loss: 0.5753 - val_precision: 0.4111 - val_recall: 0.1541\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5075 - precision: 0.5761 - recall: 0.2046 - val_loss: 0.5736 - val_precision: 0.1978 - val_recall: 0.1570\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5143 - precision: 0.5750 - recall: 0.2092 - val_loss: 0.5755 - val_precision: 0.1928 - val_recall: 0.1370\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5026 - precision: 0.5512 - recall: 0.2005 - val_loss: 0.5778 - val_precision: 0.3815 - val_recall: 0.1570\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5051 - precision: 0.5224 - recall: 0.2089 - val_loss: 0.5740 - val_precision: 0.2348 - val_recall: 0.1548\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4976 - precision: 0.5957 - recall: 0.2079 - val_loss: 0.5802 - val_precision: 0.3987 - val_recall: 0.1464\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5031 - precision: 0.5748 - recall: 0.2060 - val_loss: 0.5817 - val_precision: 0.2898 - val_recall: 0.1548\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4953 - precision: 0.5232 - recall: 0.2155 - val_loss: 0.5811 - val_precision: 0.4040 - val_recall: 0.1577\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4909 - precision: 0.5781 - recall: 0.2152 - val_loss: 0.5840 - val_precision: 0.4036 - val_recall: 0.1519\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4936 - precision: 0.5580 - recall: 0.2225 - val_loss: 0.5872 - val_precision: 0.3748 - val_recall: 0.1424\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4855 - precision: 0.5626 - recall: 0.2210 - val_loss: 0.5890 - val_precision: 0.3908 - val_recall: 0.1475\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4808 - precision: 0.5874 - recall: 0.2209 - val_loss: 0.5933 - val_precision: 0.2859 - val_recall: 0.1472\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4770 - precision: 0.6499 - recall: 0.2300 - val_loss: 0.5959 - val_precision: 0.2920 - val_recall: 0.1523\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4685 - precision: 0.6830 - recall: 0.2377 - val_loss: 0.5981 - val_precision: 0.2760 - val_recall: 0.1490\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4749 - precision: 0.7240 - recall: 0.2506 - val_loss: 0.6010 - val_precision: 0.2911 - val_recall: 0.1352\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4733 - precision: 0.7591 - recall: 0.2400 - val_loss: 0.6030 - val_precision: 0.2573 - val_recall: 0.1632\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4715 - precision: 0.7573 - recall: 0.2606 - val_loss: 0.6027 - val_precision: 0.2825 - val_recall: 0.1494\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4585 - precision: 0.7149 - recall: 0.2500 - val_loss: 0.6063 - val_precision: 0.3169 - val_recall: 0.1406\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4697 - precision: 0.7447 - recall: 0.2551 - val_loss: 0.6059 - val_precision: 0.3099 - val_recall: 0.1352\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4638 - precision: 0.7578 - recall: 0.2576 - val_loss: 0.6132 - val_precision: 0.2778 - val_recall: 0.1359\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4564 - precision: 0.7803 - recall: 0.2636 - val_loss: 0.6146 - val_precision: 0.2622 - val_recall: 0.1537\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4577 - precision: 0.7968 - recall: 0.2631 - val_loss: 0.6177 - val_precision: 0.4447 - val_recall: 0.1395\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4436 - precision: 0.7941 - recall: 0.2741 - val_loss: 0.6218 - val_precision: 0.3614 - val_recall: 0.1417\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4297 - precision: 0.7797 - recall: 0.2845 - val_loss: 0.6257 - val_precision: 0.4270 - val_recall: 0.1475\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - precision: 0.7994 - recall: 0.2860 - val_loss: 0.6318 - val_precision: 0.3379 - val_recall: 0.1577\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4350 - precision: 0.7970 - recall: 0.2933 - val_loss: 0.6334 - val_precision: 0.3675 - val_recall: 0.1443\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4330 - precision: 0.8224 - recall: 0.2934 - val_loss: 0.6305 - val_precision: 0.4124 - val_recall: 0.1486\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4247 - precision: 0.8030 - recall: 0.2958 - val_loss: 0.6392 - val_precision: 0.3528 - val_recall: 0.1515\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4124 - precision: 0.8119 - recall: 0.3018 - val_loss: 0.6442 - val_precision: 0.3184 - val_recall: 0.1501\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4242 - precision: 0.8142 - recall: 0.3110 - val_loss: 0.6449 - val_precision: 0.3781 - val_recall: 0.1413\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4168 - precision: 0.8241 - recall: 0.3163 - val_loss: 0.6483 - val_precision: 0.3458 - val_recall: 0.1643\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4032 - precision: 0.8213 - recall: 0.3265 - val_loss: 0.6522 - val_precision: 0.3549 - val_recall: 0.1483\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4024 - precision: 0.8261 - recall: 0.3190 - val_loss: 0.6585 - val_precision: 0.3352 - val_recall: 0.1515\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3874 - precision: 0.8280 - recall: 0.3344 - val_loss: 0.6594 - val_precision: 0.3174 - val_recall: 0.1450\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3955 - precision: 0.8401 - recall: 0.3425 - val_loss: 0.6695 - val_precision: 0.3385 - val_recall: 0.1570\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3819 - precision: 0.8413 - recall: 0.3531 - val_loss: 0.6751 - val_precision: 0.2988 - val_recall: 0.1545\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3797 - precision: 0.8361 - recall: 0.3629 - val_loss: 0.6833 - val_precision: 0.3243 - val_recall: 0.1581\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3726 - precision: 0.8377 - recall: 0.3719 - val_loss: 0.6893 - val_precision: 0.3010 - val_recall: 0.1614\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3756 - precision: 0.8376 - recall: 0.3655 - val_loss: 0.6962 - val_precision: 0.3060 - val_recall: 0.1566\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3765 - precision: 0.8370 - recall: 0.3802 - val_loss: 0.7028 - val_precision: 0.3116 - val_recall: 0.1432\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3743 - precision: 0.8436 - recall: 0.3807 - val_loss: 0.6964 - val_precision: 0.3358 - val_recall: 0.1639\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3569 - precision: 0.8614 - recall: 0.3912 - val_loss: 0.7032 - val_precision: 0.3369 - val_recall: 0.1705\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3480 - precision: 0.8511 - recall: 0.3980 - val_loss: 0.7131 - val_precision: 0.3080 - val_recall: 0.1658\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3376 - precision: 0.8596 - recall: 0.4161 - val_loss: 0.7145 - val_precision: 0.3170 - val_recall: 0.1607\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3457 - precision: 0.8471 - recall: 0.4172 - val_loss: 0.7300 - val_precision: 0.3043 - val_recall: 0.1599\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3281 - precision: 0.8603 - recall: 0.4297 - val_loss: 0.7365 - val_precision: 0.3220 - val_recall: 0.1851\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3315 - precision: 0.8567 - recall: 0.4496 - val_loss: 0.7299 - val_precision: 0.3349 - val_recall: 0.1774\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3316 - precision: 0.8718 - recall: 0.4332 - val_loss: 0.7599 - val_precision: 0.3241 - val_recall: 0.2000\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3196 - precision: 0.8549 - recall: 0.4813 - val_loss: 0.7744 - val_precision: 0.3152 - val_recall: 0.1760\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3089 - precision: 0.8752 - recall: 0.4686 - val_loss: 0.7545 - val_precision: 0.3130 - val_recall: 0.1621\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3170 - precision: 0.8713 - recall: 0.4609 - val_loss: 0.7576 - val_precision: 0.3353 - val_recall: 0.1756\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3040 - precision: 0.8781 - recall: 0.4898 - val_loss: 0.7891 - val_precision: 0.3164 - val_recall: 0.1934\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2951 - precision: 0.8743 - recall: 0.5016 - val_loss: 0.7715 - val_precision: 0.3176 - val_recall: 0.1821\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2966 - precision: 0.8754 - recall: 0.5111 - val_loss: 0.7820 - val_precision: 0.3260 - val_recall: 0.1785\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2912 - precision: 0.8837 - recall: 0.5106 - val_loss: 0.7992 - val_precision: 0.3143 - val_recall: 0.1847\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2847 - precision: 0.8837 - recall: 0.5133 - val_loss: 0.7995 - val_precision: 0.3222 - val_recall: 0.1974\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2772 - precision: 0.8811 - recall: 0.5360 - val_loss: 0.8148 - val_precision: 0.3117 - val_recall: 0.1701\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2765 - precision: 0.8772 - recall: 0.5382 - val_loss: 0.8348 - val_precision: 0.3026 - val_recall: 0.1679\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2715 - precision: 0.8916 - recall: 0.5401 - val_loss: 0.8224 - val_precision: 0.3079 - val_recall: 0.1851\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2551 - precision: 0.8961 - recall: 0.5639 - val_loss: 0.8310 - val_precision: 0.3149 - val_recall: 0.2018\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2624 - precision: 0.9001 - recall: 0.5593 - val_loss: 0.8371 - val_precision: 0.3167 - val_recall: 0.1781\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 - precision: 0.8994 - recall: 0.5554 - val_loss: 0.8353 - val_precision: 0.3137 - val_recall: 0.1679\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2519 - precision: 0.9027 - recall: 0.5508 - val_loss: 0.8556 - val_precision: 0.3023 - val_recall: 0.1709\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2421 - precision: 0.9093 - recall: 0.5791 - val_loss: 0.8675 - val_precision: 0.3075 - val_recall: 0.1836\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2330 - precision: 0.9025 - recall: 0.5951 - val_loss: 0.8681 - val_precision: 0.3090 - val_recall: 0.1916\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2364 - precision: 0.9015 - recall: 0.5956 - val_loss: 0.8836 - val_precision: 0.3097 - val_recall: 0.1942\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2196 - precision: 0.9087 - recall: 0.6179 - val_loss: 0.8918 - val_precision: 0.3049 - val_recall: 0.1974\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2272 - precision: 0.9088 - recall: 0.6151 - val_loss: 0.8923 - val_precision: 0.2993 - val_recall: 0.1869\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2169 - precision: 0.9175 - recall: 0.6215 - val_loss: 0.9039 - val_precision: 0.3028 - val_recall: 0.2066\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2219 - precision: 0.9179 - recall: 0.6320 - val_loss: 0.9133 - val_precision: 0.3043 - val_recall: 0.1945\n",
      "Train Precision: [0.6941716  0.92435706 0.9796748  0.98612314 0.9930265 ]\n",
      "Train Recall: [0.92414993 0.799041   0.63034004 0.4956408  0.3103749 ]\n",
      "Validation Precision: [0.2745592  0.3014354  0.30514705 0.32850242 0.312     ]\n",
      "Validation Recall: [0.3970856  0.22950819 0.15118398 0.12386157 0.07103825]\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=shared_input, outputs=outputs)\n",
    "# 编译模型，添加精确率和召回率指标\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', #将NN的值传入最终的separate models\n",
    "    metrics=[\n",
    "        tf.keras.metrics.Precision(name='precision', thresholds=[0.2, 0.5, 0.7, 0.8, 0.9]),\n",
    "        tf.keras.metrics.Recall(name='recall', thresholds=[0.2, 0.5, 0.7, 0.8, 0.9]),\n",
    "    ])\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train, Y_train, epochs=100, validation_data=(X_valid, Y_valid))\n",
    "# 计算模型在训练集上的精确率和召回率\n",
    "train_precision = history.history['precision'] \n",
    "train_recall = history.history['recall']\n",
    "\n",
    "# 计算模型在验证集上的精确率和召回率\n",
    "val_precision = history.history['val_precision']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "# 打印训练集和验证集上的精确率和召回率\n",
    "print(f'Train Precision: {train_precision[-1]}')\n",
    "print(f'Train Recall: {train_recall[-1]}')\n",
    "print(f'Validation Precision: {val_precision[-1]}')\n",
    "print(f'Validation Recall: {val_recall[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
